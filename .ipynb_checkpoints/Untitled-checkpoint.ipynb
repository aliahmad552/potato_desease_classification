{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef794282-7cae-4ef2-bfff-71f3c993ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a780e3-545d-49db-b922-b9eb887e2837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1506 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHENNELS = 3\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 10,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf0aba1-61cd-4f3b-b5cf-ac97720a7931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 431 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 10,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3dd0882-7981-4c4f-9768-0af56d524b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 215 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 10,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'dataset/val',\n",
    "    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09344623-44c7-415e-a15d-c5037ab3cfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Potato___Early_blight': 0, 'Potato___Late_blight': 1, 'Potato___healthy': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116ab209-2083-4ea6-9f16-3402956d7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a33b4ef-e4dd-4eff-b7d5-edf1084c3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "input_shape = (IMAGE_SIZE,IMAGE_SIZE,CHENNELS)\n",
    "\n",
    "class_num = 3\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape =input_shape),\n",
    "    layers.Conv2D(32,(3,3),activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size = (3,3),activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size = (3,3),activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size = (2,2),activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size = (2,2),activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size = (3,3),activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation = 'relu'),\n",
    "    layers.Dense(class_num,activation = 'softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054eba82-b0d4-47cc-9797-95b8d6f2a932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 29, 29, 64)        16448     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 64)        16448     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 2, 2, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 142787 (557.76 KB)\n",
      "Trainable params: 142787 (557.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c64e54-764e-4490-84f4-06a1ca443c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d500a61-9312-46fb-97b0-324359a120c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 [==============================] - 150s 3s/step - loss: 0.8934 - accuracy: 0.5129 - val_loss: 0.8697 - val_accuracy: 0.6094\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 147s 3s/step - loss: 0.6749 - accuracy: 0.6635 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 167s 4s/step - loss: 0.4311 - accuracy: 0.8168 - val_loss: 0.4151 - val_accuracy: 0.8229\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.2910 - accuracy: 0.8853 - val_loss: 0.3159 - val_accuracy: 0.8542\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 175s 4s/step - loss: 0.2816 - accuracy: 0.8860 - val_loss: 0.2226 - val_accuracy: 0.9115\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 175s 4s/step - loss: 0.1840 - accuracy: 0.9322 - val_loss: 0.1380 - val_accuracy: 0.9531\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 185s 4s/step - loss: 0.1127 - accuracy: 0.9559 - val_loss: 0.1138 - val_accuracy: 0.9635\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 189s 4s/step - loss: 0.1694 - accuracy: 0.9315 - val_loss: 0.0945 - val_accuracy: 0.9635\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 175s 4s/step - loss: 0.1103 - accuracy: 0.9566 - val_loss: 0.0876 - val_accuracy: 0.9635\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 173s 4s/step - loss: 0.1096 - accuracy: 0.9579 - val_loss: 0.0710 - val_accuracy: 0.9844\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 173s 4s/step - loss: 0.1342 - accuracy: 0.9484 - val_loss: 0.1101 - val_accuracy: 0.9583\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 172s 4s/step - loss: 0.0755 - accuracy: 0.9708 - val_loss: 0.0347 - val_accuracy: 0.9948\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 170s 4s/step - loss: 0.1023 - accuracy: 0.9634 - val_loss: 0.0596 - val_accuracy: 0.9792\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 175s 4s/step - loss: 0.0709 - accuracy: 0.9708 - val_loss: 0.0970 - val_accuracy: 0.9688\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 176s 4s/step - loss: 0.1130 - accuracy: 0.9573 - val_loss: 0.1738 - val_accuracy: 0.9115\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 178s 4s/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.0523 - val_accuracy: 0.9844\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 178s 4s/step - loss: 0.0400 - accuracy: 0.9858 - val_loss: 0.1062 - val_accuracy: 0.9583\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 178s 4s/step - loss: 0.1070 - accuracy: 0.9586 - val_loss: 0.0930 - val_accuracy: 0.9688\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 226s 5s/step - loss: 0.0649 - accuracy: 0.9803 - val_loss: 0.0532 - val_accuracy: 0.9792\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 219s 5s/step - loss: 0.0346 - accuracy: 0.9858 - val_loss: 0.0348 - val_accuracy: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x201c4217e20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "         steps_per_epoch = 47,\n",
    "         batch_size = 32,\n",
    "         validation_data = val_generator,\n",
    "         validation_steps = 6,\n",
    "         epochs = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c921d5-7649-45b4-b7bb-84e5fa409c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "663bb27f-cc79-48a6-9043-18500e82eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c649f61-4bf8-4019-bfc7-7f2f81672f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../potatoes.h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../potatoes.h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../potatoes.h5'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  Args:\n",
      "    args_0: float32 Tensor, shape=(None, 256, 256, 3)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(None, 3)\n"
     ]
    }
   ],
   "source": [
    "model.export('../potatoes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cfebc93-dec8-4450-a017-6bae7af8f288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 18s 1s/step - loss: 0.0497 - accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04966973885893822, 0.9860788583755493]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af6640-ab52-4c35-aa74-566f69e339d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
